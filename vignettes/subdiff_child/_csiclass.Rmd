# User-Defined Models

The **subdiff** tools can be applied to a large family of user-defined models.   These are based on the location-scale modeling framework of @lysy.etal16, whereby the particle trajectory $\XX(t)$ is given by
\begin{equation}
  \XX(t) = \RR(t \mid \pph)' \mmu + \SSi^{1/2} \ZZ(t),
  (\#eq:locscale)
\end{equation}
where:

- $\ZZ(t) = \big(Z_1(t), \ldots, Z_{\ndim}(t)\big)$ are independent and identically distributed (iid) copies of a CSI process $Z(t)$ having MSD

	$$
	\msd_Z(t) = \eta(t \mid \pph).
	$$

- $\SSi$ is a $\ndim \times \ndim$ symmetric positive-definite scaling matrix.

- $\RR(t \mid \pph) = \big( R_1(t \mid \pph), \ldots, R_{\ndrift}(t \mid \pph) \big)$ is a set of $\ndrift$ drift basis functions.  Typically it will be linear or quadratic, corresponding to $\RR(t) = t$ and $\RR(t) = (t, t^2)$ with $\ndrift = 1$ and $\ndrift = 2$, respectively.  However, **subdiff** allows for an arbitrary number of basis functions possibly dependent on the "kernel" parameters $\pph$.

- $\mmu$ is $\ndrift \times \ndim$ matrix of drift coefficients.  For linear drift, $\mmu = (\rv \mu \ndim)$ correspond to per-coordinate drift velocities.

An attractive feature of model \@ref(eq:locscale) is that the MSD of the drift-subtracted particle trajectory $\tilde{\XX}(t) = \XX(t) - \RR(t)' \mmu$ has the simple formula

$$
\msd_{\tilde{\XX}} = \tfrac 1 {\ndim} \tr(\SSi) \cdot  \eta(t \mid \pph).
$$

Another appealing property of this model is that its parameters $\tth = (\pph, \mmu, \SSi)$ can be estimated from discrete observations $\XX = (\rv [0] {\XX} N)$ in a computationally efficient manner [@ling.lysy20].

## Example: Brownian Motion in a Jeffreys Fluid

Consider a particle of radius $r$ in a Jeffreys fluid described by viscosity parameters $\eta_1$ and $\eta_2$ and elastic modulus $\Gamma$.  The MSD of the drift-subtracted particle trajectory $\tilde{\XX}(t)$ is given by [@raikher.rusakov10]

\begin{equation}
\msd_{\tilde{\XX}}(t) = \frac{2 \kbt}{\xi_V(1+q)} \times \left\{t + \frac{q}{1+q} \tau_M \left[1 - \exp\left(-\frac{(1+q)t}{\tau_M}\right)\right]\right\},
(\#eq:jfsmsd)
\end{equation}

where $q = \eta_1/\eta_2$, $\tau_M = (\eta_1 + \eta_2)/\Gamma$, $\xi_V = 6\pi r \cdot \eta_1\eta_2/(\eta_1 + \eta_2)$, and $T$ and $r$ are the temperature of the system and radius of the particle, respectively.  A more natural parametrization is

$$
\msd_{\tilde{\XX}}(t) = \sigma^2 \left\{t + \alpha \left[1 - e^{-t/\tau}\right]\right\},
$$

where $\tau = \tau_M/(1+q) = \eta_2/\Gamma$, $\alpha = \tau q = \eta_1/\Gamma$, and $\sigma^2 = 2\kbt / (\xi_V(1+q)) = 2\kbt / (6\pi r \eta_1)$.  In the formulation of the location-scale model \@ref(eq:locscale), the CSI process $Z(t)$ underlying the particle trajectory $\XX(t)$ has MSD

$$
\eta(t \mid \pph) = \msd_Z(t) = \left\{t + \alpha \left[1 - e^{-t/\tau}\right]\right\}
$$

with $\pph = (\alpha, \tau)$, and the MSD scale factor is $\sigma^2 = \tr(\SSi)/\ndim$.

## Creating the Jeffreys Model Class

In order to fit the Jeffreys model \@ref(eq:jfsmsd) to trajectory data, we will create a class `jfs_model` which will derive from the base class `csi_model` used to represent the general location-scale model \@ref(eq:locscale).  In order to do this, we will need the following ingredients:

- The increment autocorrelation function

	$$
	\acf_{\Delta Z}(h) = \cov(\Delta Z_n, \Delta Z_{n+h}).
	$$

	This must be supplied as a function with arguments $(\pph, \dt, N)$ and return the vector $\big(\acf_{\Delta Z}(0), \ldots, \acf_{\Delta Z}(N-1)\big)$.  Note that $\msd_{Z}(t)$ can be converted to $\acf_{\Delta Z}(h)$ via the function `SuperGauss::msd2acf()`.

- Functions to convert back and forth between the kernel parameters in the "inferential" basis, $\pph$, and these parameters in a "computational basis", $\pps$.  That is, $\pps$ should have the same dimension as $\pph$ but have no constraints.  For the Jeffreys model, since $\alpha, \tau > 0$, a natural choice of computational basis is $\pps = (\log \alpha, \log \tau)$.

- Specification of the drift basis functions $\RR(t \mid \pph)$.  This is done automatically in the case of linear, quadratic, or no drift, so we'll skip this here.

- A character vector of the names of the elements of $\pph$ for display purposes.

The following code block defines the `jfs_model` class.  This is done with the [R6](https://r6.r-lib.org/index.html) class mechanism, of which a basic understanding is assumed.  More information about the base class for location-scale models can be obtained from the package documentation: `?csi_model`.

```{r jfs_model}
#' Calculate the ACF of the Jeffreys model.
#'
#' @param alpha Scale parameter.
#' @param tau Decorrelation time.
#' @param dt Interobservation time.
#' @param N Number of ACF lags to return.
#'
#' @return An ACF vector of length `N`.
jfs_acf <- function(alpha, tau, dt, N) {
  t <- (1:N)*dt # time vector
  msd <- (t + alpha * (1 - exp(-t/tau)))
  SuperGauss::msd2acf(msd) # convert msd to acf
}

jfs_model <- R6::R6Class(
  classname = "jfs_model",
  inherit = subdiff::csi_model,

  public = list(
    # Kernel parameter names in the inferential basis.
    phi_names = c("alpha", "tau"),

    # Autocorrelation function.
    acf = function(phi, dt, N) {
      jfs_acf(alpha = phi[1], tau = phi[2], dt = dt, N = N)
    },

    # Transform kernel parameters from inferential to computational basis.
    trans = function(phi) {
      psi <- log(phi)
      names(psi) <- private$psi_names # these are determined automatically.
      psi
    },

    # Transform kernel parameters from computational to inferential basis.
    itrans = function(psi) {
      phi <- exp(psi)
      names(phi) <- self$phi_names
      phi
    }
  )
)
```

## Simulation

```{r jfs_sim_calc, include = FALSE}
kB <- 1.38064852e-23 # Boltzmann constant

# simulation parameters
tau_M <- 2.1 # seconds
q <- 4.6e1 # unitless
xi_V <- 1.4e-07 # kg/s
Temp <- 298 # temperature of the system (Kelvin)

dt <- 1/60 # interobservation time
N <- 1800 # number of observations
ndim <- 2 # number of dimensions

# increment autocorrelation
tau <- tau_M/(1+q)
alpha <- tau * q
acf <- jfs_acf(alpha = alpha, tau = tau, dt = dt, N = N)
# increment drift matrix: in this case zero drift
drift <- matrix(0, N, ndim)
# scale matrix (micron^2)
sigma2 <- 1e12 * 2*kB*Temp / (xi_V * (1+q))
Sigma <- sigma2 * diag(ndim)
# position at time t = 0
X0 <- rep(0, ndim)

# generate data
Xt <- csi_sim(drift = drift, acf = acf,
              Sigma = Sigma, X0 = X0)

# plot empirical and theoretical MSD
tmax <- 10 # maximum time to plot
nmax <- floor(tmax/dt) # corresponding MSD lag number
tibble(
  Time = 1:nmax * dt, # time sequence
  Theoretical = sigma2 * SuperGauss::acf2msd(acf[1:nmax]), # theoretical msd
  Empirical = msd_fit(Xt, nlag = nmax) # empirical msd
) %>%
  pivot_longer(cols = Theoretical:Empirical, names_to = "MSD Type",
               values_to = "MSD", values_ptypes = list(factor())) %>%
  ggplot(aes(x = Time, y = MSD, group = `MSD Type`)) +
  geom_line(aes(color = `MSD Type`)) +
  scale_x_log10() + scale_y_log10() +
  xlab(expression("Time "*(s))) + ylab(expression("MSD "*(mu*m^2)))
```

<!-- In @raikher.rusakov10, the Jeffreys model \@ref(eq:jfsmsd) is calibrated to particles of radius $r = `r NA`\, \mathrm{\mu m}$ in a solution of cetyltrimethyl ammonium bromide $[\mathrm{CTAB}] = 1\, \mathrm{g}\, \mathrm{cm}^{-3}$ and potassium bromide $[\mathrm{KBr}] = 2\, \mathrm{M}$ at temperature $T = `r Temp`\, \mathrm{K}$.  The fitted parameters are $\tau_M = `r tau_M`\, \mathrm{s}$, $q = `r q`$, and $\xi_V = `r xi_V`\, \mathrm{kg/s}$. -->

The following code shows how to simulate the trajectory of a particle from the Jeffreys model with parameters $\tau_M = `r tau_M`\, \mathrm{s}$, $q = `r q`$, and $\xi_V = `r xi_V`\, \mathrm{kg/s}$ and temperature $T = `r Temp`\, \mathrm{K}$.  The 2D trajectory is generated with zero drift $\RR(t \mid \pph) = 0$, and scale factor $\SSi = \left[\begin{smallmatrix} \sigma^2 & 0 \\ 0 & \sigma^2 \end{smallmatrix} \right]$.  Figure \@ref(fig:jfssim) compares the empirical MSD for the simulated trajectory to the theoretical MSD.

(ref:jfssim) Empirical and theoretical MSD for the Jeffreys model with parameters $\tau_M = `r tau_M`\, \mathrm{s}$, $q = `r q`$, and $\xi_V = `r xi_V`\, \mathrm{kg/s}$ and temperature $T = `r Temp`\, \mathrm{K}$.

```{r jfssim, ref.label = "jfs_sim_calc", fig.width = 7, fig.height = 3, fig.cap = "(ref:jfssim)"}
```

## Parameter Estimation

The `jfs_model` class inherits from the base class `csi_model`, which contains a number of methods to assist with parameter estimation.  In the following example, we'll use these to calculate the MLE of the Jeffreys fluid parameters $\zze = (\eta_1, \eta_2, \Gamma)$ along with their standard errors.  This proceeds in several steps:

### Step 1: Profile Likelihood

The first step is to calculate the MLE of the kernel parameters $\pph = (\alpha, \tau)$.  Let $\ell(\tth \mid \XX) = \ell(\pph, \mmu, \SSi \mid \XX)$ denote the loglikelihood function for the complete set of parameters.  As noted in @ling.etal19,

$$
(\hat{\mmu}_{\pph}, \hat{\SSi}_{\pph}) = \argmax_{(\mmu, \SSi)} \ell(\pph, \mmu, \SSi \mid \XX)
$$
	
is available in closed-form, from which we may calculate the so-called [profile likelihood](https://en.wikipedia.org/wiki/Likelihood_function#Profile_likelihood) function

\begin{equation}
\begin{aligned}
\ell_{\tx{prof}}(\pph \mid \XX) &= \max_{\mmu, \SSi} \ell(\pph, \mmu, \SSi \mid \XX) \\
& = \ell(\pph, \hat{\mmu}_{\pph}, \hat{\SSi}_{\pph} \mid \XX).	
\end{aligned}
(\#eq:llprof)
\end{equation}

It follows that if $\hat{\pph} = \argmax_{\pph} \ell_{\tx{prof}}(\pph \mid \XX)$, then the MLE of $\tth = (\pph, \mmu, \SSi)$ is given by

$$
\hat{\tth} = (\hat{\pph}, \hat{\mmu}_{\hat{\pph}}, \hat{\SSi}_{\hat{\pph}}).
$$

The upshot of this technique is that $\hat{\tth}$ can be obtained by maximizing $\ell_{\tx{prof}}(\pph \mid \XX)$ rather than $\ell(\tth \mid \XX)$.  The former is a lower-dimensional optimization problem, and thus more computationally efficient.

The following code shows how to calculate $\hat{\tth}$.  Note that the optimization of the profile likelihood \@ref(eq:llprof) is done with respect to $\pps$, the kernel parameters in the computational basis.  We'll use the function `stats::optim()` for this.

```{r jfs_nlp}
# construct the model object
mod <- jfs_model$new(Xt = Xt, dt = dt)

# minimize the negative profile likelihood.
opt <- optim(fn = mod$nlp, # negative profile likelihood
             par = c(0, 0)) # initial value of psi

# mle of psi
psi_hat <- opt$par
psi_hat
```

Before going further, it is sometimes useful to check whether `stats::optim()` has indeed converged.  One way to do this is by examining the convergence flag:

```{r jfs_optconv}
opt$convergence
```

A value of zero means `stats::optim()` thinks it has converged.  Any other value means it hasn't converged (details in the function documentation).  However, the convergence metric used by `stats::optim()` is sometimes unreliable.  A more reliable but slower convergence diagnostic is to look at projection plots.  The process is facilitated with the use of the R package `r cran_link("optimCheck")`.

```{r jfsproj, fig.width = 7, fig.height = 3, fig.cap = "Projection plots for profile likelihood maximization.  Red lines correspond to values of the candidate solution."}
optimCheck::optim_proj(fun = mod$nlp, # function to minimize
                       xsol = psi_hat, # candidate for local minimum
                       xnames = expression(log(alpha), log(tau)), # parameter names
                       maximum = FALSE) # check minimum not maximum
```

The red lines in Figure \@ref(fig:jfsproj) correspond to the values of the candidate solution $\pps$.  The fact that each of these values is at the minimum of the projection plot of the corresponding negative profile loglikelihood function indicates that `stats::optim()` has found a local optimum.  We can now convert $\hat{\pps}$ into the MLE of $\tth$:

```{r jfs_mle}
phi_hat <- mod$itrans(psi = psi_hat) # convert psi to inferential basis (phi)
nu_hat <- mod$nu_hat(phi = phi_hat) # calculate nu_hat = (mu_hat, Sigma_hat)
theta_hat <- list(phi = phi_hat, mu = nu_hat$mu, Sigma = nu_hat$Sigma)
theta_hat
```

### Step 2: Variance Estimation

The variance of the MLE, $\var(\hat{\tth})$, is estimated by $\VV(\hat{\tth})$, the inverse of the [observed Fisher information matrix](https://en.wikipedia.org/wiki/Observed_information),

$$
\VV(\hat{\tth}) = \left[- \frac{\partial^2}{\partial \tth \partial \tth'} \ell(\hat{\tth} \mid \XX)\right]^{-1}.
$$

The confidence interval for a given parameter $\theta_j$ is then given by $\hat \theta_j \pm 2 \se(\hat \theta_j)$, where the standard error is $\se(\hat \theta_j) = \sqrt{[\VV(\hat{\tth})]_{jj}}$.

The **subdiff** package calculates the variance estimate using numerical differentiation via the R package `r cran_link("numDeriv")`.  However, rather than calculating the Hessian of the loglikelihood with respect to the inferential basis $\tth$, **subdiff** instead does this with respect to a computational basis $\oom = (\pps, \mmu, \lla)$, where $\lla$ is the log-Cholesky decomposition of $\SSi$.  That is, for $\SSi_{\ndim \times \ndim}$, $\lla$ is a vector of size $\ndim(\ndim+1)/2$ corresponding to the upper Cholesky factor of $\SSi$ in column-major order, but with the log of its diagonal elements.  In other words, if
$$
\UU_{\ndim \times \ndim} = \begin{bmatrix} 
\exp(\lambda_1) & \lambda_2 & \cdots & \lambda_{\ndim(\ndim-1)/2 + 1} \\
0 & \exp(\lambda_3) & \cdots & \lambda_{\ndim(\ndim-1)/2 + 2} \\
\vdots & & \ddots & \vdots \\
0 & 0 & \cdots & \exp(\lambda_{\ndim(\ndim-1)/2+\ndim})
\end{bmatrix},
$$
then $\UU$ is the unique upper-triangular matrix with positive diagonal elements such that $\SSi = \UU'\UU$.  The vector $\lla$ is unconstrained in $\mathbb{R}^{\ndim(\ndim-1)/2+\ndim}$, and consequently $\oom$ is unconstrained in $\mathbb{R}^{\operatorname{dim}(\oom)}$ as well, which make the numerical Hessian calculation more stable and more accurate.  Moreover, the estimators $\hat{\oom}$ and $\VV(\hat{\oom})$ can be easily used to calculate standard errors and confidence intervals for any parameter of interest as we shall see [below](#deltamethod).

The following R code shows how to calculate $\hat{\oom}$ and $\VV(\hat{\oom})$.

```{r jfs_var}
# convert theta to computational basis (omega)
omega_hat <- mod$trans_full(phi = theta_hat$phi,
                            mu = theta_hat$mu,
                            Sigma = theta_hat$Sigma)
# calculate fisher information matrix
fi_obs <- mod$fisher(omega_hat)
# stable inversion of fisher information
omega_var <- mod$get_vcov(fi_obs)
list(coef = signif(omega_hat, 2),
     vcov = signif(omega_var, 2))
```

### Step 3: Estimating Arbitrary Quantities of Interest {#deltamethod}

```{r jfs_zeta_calc, include = FALSE}
#' Calculate the Jeffreys model parameters from the parameters of the computational basis.
#'
#' @param omega Vector of computational basis parameters.
#' @param model Jeffreys model object of class `jfs_model`.  This is used to convert `omega` to the inferential basis `theta = (phi, mu, Sigma)`.
#' @param rad Radius of the particle (m).
#' @param Temp Temperature of the system (Kelvin).
#' 
#' @return A vector with named elements `eta1` (N s / m^2), `eta2` (N s / m^2), and `Gamma` (kg / (m s^2)).
jfs_zeta <- function(omega, model, rad, Temp) {
  kB <- 1.38064852e-23 # Boltzmann constant: m^2 kg /(s^2 K)
  # convert omega to theta
  theta <- model$itrans_full(omega)
  # parameters in simplified basis
  alpha <- theta$phi["alpha"]
  tau <- theta$phi["tau"]
  sigma2 <- mean(diag(theta$Sigma)) * 1e-12 # convert from micron^2 to m^2
  # parameters in original basis
  eta1 <- 2*kB*Temp / (6*pi*rad * sigma2)
  Gamma <- eta1/alpha
  eta2 <- tau*Gamma
  setNames(c(eta1, eta2, Gamma), c("eta1", "eta2", "Gamma"))
}

# estimate of zeta

rad <- 0.48 # particle radius (micron)
Temp <- 298 # temperature of the system (Kelvin)

# point estimate
zeta_hat <- jfs_zeta(omega = omega_hat,
                     model = mod,
                     rad = rad * 1e-6, # micron -> m
                     Temp = Temp)

# variance estimate
# jacobian is returned as a matrix of size `length(zeta) x length(omega)`
jac <- numDeriv::jacobian(
                   func = function(omega) {
                     jfs_zeta(omega,
                              model = mod, rad = rad*1e-6, Temp = Temp)
                   },
                   x = omega_hat
                 )
zeta_var <- jac %*% omega_var %*% t(jac)
colnames(zeta_var) <- rownames(zeta_var) <- names(zeta_hat)

list(coef = signif(zeta_hat, 2),
     vcov = signif(zeta_var, 2))
```


Let $\pps = (\psi_1, \ldots, \psi_P) \in \mathbb R^{P}$, for which we have the MLE $\hat{\pps}$ and its variance estimate $\VV(\hat{\pps})$.  Now suppose we wish to estimate the quantity of interest $\zze = \bm{G}(\pps) = \big(G_1(\pps), \ldots, G_Q(\pps)\big) \in \mathbb R^{Q}$.  Then the point estimate is $\hat{\zze} = \bm{G}(\hat{\pps})$, and the corresponding variance estimate is

$$
\VV(\hat{\zze}) = \JJ(\hat{\pps})' \VV(\hat{\pps}) \JJ(\hat{\pps}),
$$

where $\JJ(\pps)$ is the $P \times Q$ Jacobian matrix with elements $[\JJ(\pps)]_{ij} = \frac{\partial}{\partial \psi_i} G_j(\pps)$.  The code below shows how to do this for the Jeffreys model parameters $\zze = (\eta_1, \eta_2, \Gamma)$ for a particle of radius $r = `r rad` \, \mu\mathrm{m}$ at temperature $T = `r Temp`\, \mathrm{K}$.  The Jacobian matrix $\JJ(\hat{\pps})$ is calculated numerically using `numDeriv::jacobian()`.

```{r jfs_zeta, ref = "jfs_zeta_calc"}
```

Finally we can convert the variance matrix estimate to standard errors and 95% confidence intervals for each element of $\zze$.

```{r jfs_zeta_se}
# standard errors
zeta_se <- sqrt(diag(zeta_var))

# display point estimate, standard error, and confidence interval
disp <- cbind(est = zeta_hat,
              se = zeta_se,
              `2.5%` = zeta_hat - 2*zeta_se,
              `97.5%` = zeta_hat + 2*zeta_se)
signif(disp, 2)
```

```{r scratch, eval = FALSE, include = FALSE}
#' Convert original parameters to standardized parameters for the Jeffreys model.
#'
#' @param eta1 First viscosity parameter (positive real).
#' @param eta2 Second viscosity parameter (positive real).
#' @param Gamma The elastic modulus of the fluid (positive real).
#' @param Temp Temperature of the system.
#'
#' @return Vector of standardized parameters `(tau_M, q, xi_V)`.
jfs_stpar <- function(eta1, eta2, Gamma, Temp) {
  
}


#' Calculate the MSD of the Jeffreys model.
#'
#' @param t Vector of timepoints at which to calculate the MSD.
#' @param rad Radius of the particle.
#' @param eta1 First viscosity parameter.
#' @param eta2 Second viscosity parameter.
#' @param Gamma The elastic modulus of the fluid.
#' @param Temp Temperature of the system.
#'
#' @return MSD vector of the same length as `t`.
jfs_msd <- function(t, rad, eta1, eta2, Gamma, Temp) {
  Kb <- 1.381e-23 # Boltzmann's constant
  tau <- eta2/Gamma
  alpha <- eta1/Gamma
  sigma2 <- 2*Kb*Temp / (6*pi*rad * eta1)
  sigma2 * (t + alpha * (1 - exp(-abs(t)/tau)))
}

# Calculate the standardized parametrization
jfs_std <- function(alpha, tau, sigma2, Temp) {
  kB <- 1.38064852e-23 # Boltzmann constant ( m^2 kg /(s^2 K) )
  q <- alpha/tau
  tau_M <- tau * (1+q)
  xi_V <- 2*kB*Temp/(sigma2 * (1+q))
  setNames(c(tau_M, q, xi_V), c("tau_M", "q", "xi_V"))
}
# Calculate the natural parametrization
jfs_nat <- function(tau_M, q, xi_V, Temp) {
  kB <- 1.38064852e-23 # Boltzmann constant
  sigma2 <- 2*kB*Temp/(xi_V * (1+q))
  alpha <- q/(1+q) * tau_M
  tau <- tau_M/(1+q)
  setNames(c(alpha, tau, sigma2), c("alpha", "tau", "sigma2"))
}
# Calculate MSD
jfs_msd <- function(t, tau_M, q, xi_V, Temp) {
  ## kB <- 1.38064852e-23 # Boltzmann constant
  ## sigma2 <- 2*kB*Temp/(xi_V * (1+q))
  ## alpha <- q/(1+q) * tau_M
  ## tau <- tau_M/(1+q)
  theta_nat <- jfs_nat(tau_M, q, xi_V, Temp)
  alpha <- theta_nat[1]
  tau <- theta_nat[2]
  sigma2 <- theta_nat[3]
  sigma2 * (t + alpha * (1 - exp(-t/tau)))
}

tau_M <- 1.8e1 # seconds
q <- 6.7e1 # unitless
xi_V <- 1.2e-10 # kg/s
rad <- 0.48 # particle radius (micron)
Temp <- 298 # temperature of the system (Kelvin)
theta_std <- c(tau_M = tau_M, q = q, xi_V = xi_V)
theta_nat <- do.call(jfs_nat, as.list(c(theta_std, Temp = Temp)))
do.call(jfs_std, as.list(c(theta_nat, Temp = Temp))) - theta_std

tseq <- exp(seq(log(1/60), log(30), len = 1000))
alpha <- 8.2
tau <- 4.6e-2
sigma2 <- 9.1e-15
plot(tseq, 1e12 * sigma2 * (tseq + alpha * (1 - exp(-tseq/tau))),
     type = "l", log = "xy", xlab = "Time (s)", ylab = "MSD (microns^2)")

```
